# AutoControl-Bench ğŸš—ğŸ§ 

A benchmark for ambiguous vehicle-control commands: parse fuzzy single-turn instructions, ask clarifications, and execute structured function calls.

## ğŸ” Overview
- **3 tiers**:  
  1. Single-turn fuzzy parsing  
  2. Extreme ambiguity â†’ clarify  
  3. Multi-turn dialogue â†’ execute  
- **Data**: 20 000 samples (6 k single-turn, 8 k clarification, 6 k dialogues)  
- **Domains**: navigation, HVAC, media, lights, etc.

## âœ¨ Key Features
- **9 ambiguity types** (e.g. referential vagueness, missing parameters)  
- **Multi-turn context**: maintain history & refine intent  
- **Protocol compliance**: only  
  - `function_call(name, params)`  
  - or a formatted clarification question  
- **Extensible**: add new functions, ambiguity types, models

## ğŸ“ Repository Structure

```bash
AutoControl-Bench/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ tier1_single_turn.json
â”‚   â”œâ”€â”€ tier2_fuzzy_clarify.json
â”‚   â”œâ”€â”€ tier3_multi_turn.json
â”‚   â””â”€â”€ protocol/
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ create_ddatasets.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ croissant_metadata.json
â”œâ”€â”€ README_zh.md
â””â”€â”€ README.md
```

```bash
ğŸ“„ Dataset Format (JSON)
Each sample in the benchmark includes:
{
  "id": "multi_001",
  "tier": "Tier-3",
  "dialogue": [
    {"user": "Turn the lights on.", "assistant": "Which lights? Headlights or interior?"},
    {"user": "Headlights, please."}
  ],
  "target_call": {
    "function": "control_lighting",
    "parameters": {"zone": "headlights", "state": "on"}
  },
  "meta": {
    "ambiguity_type": "underspecification",
    "protocol_compliant": true
  }
}
```

## ğŸ“¦ Quick Start

```bash
git clone [https://github.com/â€¦/AutoControl-Bench.git](https://github.com/HangerAmber/AutoBench-Data.git)
cd AutoBench-Data
pip install -r requirements.txt
```

```bash
python scripts/create_datasets.py
```

## âš™ï¸ Metrics
- **IRA**: Intent Recognition Accuracy  
- **PEP**: Parameter Extraction Precision  
- **FDR**: Fuzzy Detection Rate  
- **CQC**: Counter-Question Coverage  
- **DC**: Dialogue Consistency  
- **FESR**: Final Execution Success Rate  

## ğŸ“‘ Baseline
| Model         | IRA  | PEP  | FDR  | CQC  | DC   | FESR |
|---------------|-----:|-----:|-----:|-----:|-----:|-----:|
| Zero-shot LLM |  70% |  68% |  60% |  55% |  65% |  70% |
| **Fine-tuned**| **85%** | **80%** | **80%** | **75%** | **78%** | **84%** |

## ğŸ“œ Citation
```bibtex
@inproceedings{AutoControlBench2025,
  title     = {AutoControl-Bench: A Multi-Agent Knowledge Distillation Framework for Complex Vehicle Function Call Understanding},
  author    = {Anonymous et al.},
  booktitle = {NeurIPS 2025},
  year      = {2025}
}
```
